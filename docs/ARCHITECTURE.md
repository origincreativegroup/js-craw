# System Architecture

> **Note:** This architecture document is partially outdated. The system now includes:
> - Company-based crawling (Greenhouse, Lever, Generic, Indeed, LinkedIn)
> - React TypeScript frontend
> - AI job filtering and ranking (hourly)
> - Automated document generation (daily at 3 PM)
> - Task management system
> - Company discovery and lifecycle management
> - See [ENHANCEMENT_PLAN.md](ENHANCEMENT_PLAN.md) for current implementation status

## Component Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Job Search Crawler                      â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚                 Web Dashboard (FastAPI)             â”‚     â”‚
â”‚  â”‚  â€¢ React/HTML Frontend                              â”‚     â”‚
â”‚  â”‚  â€¢ REST API                                         â”‚     â”‚
â”‚  â”‚  â€¢ WebSocket for real-time updates (optional)      â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                           â”‚                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚              Scheduler (APScheduler)                â”‚     â”‚
â”‚  â”‚  Runs every 30 minutes                              â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                           â”‚                                   â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚         â”‚                                     â”‚               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                     â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚   LinkedIn  â”‚                     â”‚   Indeed     â”‚       â”‚
â”‚  â”‚   Crawler   â”‚                     â”‚   Crawler    â”‚       â”‚
â”‚  â”‚  (Selenium) â”‚                     â”‚  (Selenium)  â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚         â”‚                                     â”‚               â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                           â”‚                                   â”‚
â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚                  â”‚  AI Analyzer    â”‚                         â”‚
â”‚                  â”‚    (Ollama)     â”‚                         â”‚
â”‚                  â”‚  â€¢ Match scoring â”‚                        â”‚
â”‚                  â”‚  â€¢ Job summaries â”‚                        â”‚
â”‚                  â”‚  â€¢ Pros/Cons     â”‚                        â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                           â”‚                                   â”‚
â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚                  â”‚   PostgreSQL    â”‚                         â”‚
â”‚                  â”‚   â€¢ Jobs        â”‚                         â”‚
â”‚                  â”‚   â€¢ Searches    â”‚                         â”‚
â”‚                  â”‚   â€¢ Follow-ups  â”‚                         â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                           â”‚                                   â”‚
â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚                  â”‚  Notifications  â”‚                         â”‚
â”‚                  â”‚  â€¢ ntfy.sh      â”‚â”€â”€â”€â”€> ðŸ“± Phone          â”‚
â”‚                  â”‚  â€¢ Pushover     â”‚                         â”‚
â”‚                  â”‚  â€¢ Telegram     â”‚                         â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## File Structure

```
job-crawler/
â”œâ”€â”€ docker-compose.yml          # Orchestrates all services
â”œâ”€â”€ Dockerfile                  # Main app container
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ main.py                     # Application entry point
â”œâ”€â”€ start.sh                    # Quick start script
â”œâ”€â”€ .env.example                # Environment template
â”œâ”€â”€ README.md                   # Full documentation
â”œâ”€â”€ SETUP.md                    # Quick setup guide
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py              # Configuration & settings
â”‚   â”œâ”€â”€ database.py            # Database connection
â”‚   â”œâ”€â”€ models.py              # SQLAlchemy models
â”‚   â”œâ”€â”€ api.py                 # FastAPI routes
â”‚   â”‚
â”‚   â”œâ”€â”€ crawler/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ linkedin_crawler.py    # LinkedIn automation
â”‚   â”‚   â”œâ”€â”€ indeed_crawler.py      # Indeed automation
â”‚   â”‚   â””â”€â”€ orchestrator.py        # Coordinates crawlers
â”‚   â”‚
â”‚   â”œâ”€â”€ ai/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ analyzer.py            # Ollama integration
â”‚   â”‚
â”‚   â”œâ”€â”€ notifications/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ notifier.py            # Push notifications
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ crypto.py              # Password encryption
â”‚
â””â”€â”€ static/
    â””â”€â”€ index.html              # Web dashboard
```

## Data Flow

1. **Scheduled Trigger** (every 30 min)
   â””â”€> Orchestrator

2. **Orchestrator**
   â”œâ”€> Retrieves active search criteria from DB
   â”œâ”€> Gets encrypted credentials
   â””â”€> Spawns crawlers for each platform

3. **Crawlers** (LinkedIn/Indeed)
   â”œâ”€> Login with Selenium
   â”œâ”€> Execute searches
   â”œâ”€> Parse job listings
   â””â”€> Return raw job data

4. **AI Analyzer**
   â”œâ”€> Receives job data
   â”œâ”€> Calls Ollama API
   â”œâ”€> Generates summary, pros/cons
   â”œâ”€> Calculates match score
   â””â”€> Returns analysis

5. **Database**
   â”œâ”€> Checks for duplicates
   â”œâ”€> Saves new jobs with analysis
   â””â”€> Updates metadata

6. **Notification Service**
   â”œâ”€> Aggregates new jobs
   â”œâ”€> Formats message
   â””â”€> Sends to phone

7. **Dashboard**
   â”œâ”€> User views jobs
   â”œâ”€> Updates status
   â”œâ”€> Manages searches
   â””â”€> Tracks applications

## API Endpoints

### Search Management
- `GET /api/searches` - List all searches
- `POST /api/searches` - Create new search
- `PATCH /api/searches/{id}` - Update search
- `DELETE /api/searches/{id}` - Delete search

### Job Management
- `GET /api/jobs` - List jobs (with filters)
- `GET /api/jobs/{id}` - Get job details
- `PATCH /api/jobs/{id}` - Update job status

### Follow-ups
- `GET /api/followups` - List follow-ups
- `POST /api/followups` - Create follow-up

### System
- `POST /api/crawl/run` - Trigger manual crawl
- `GET /api/stats` - Dashboard statistics
- `POST /api/credentials` - Save platform credentials

## Database Schema

### Users
- Platform credentials (encrypted)
- Email, password hash
- Active status

### SearchCriteria
- Keywords, location, filters
- Associated platforms
- Active/inactive toggle
- Notification preferences

### Jobs
- Job details (title, company, etc.)
- Platform metadata
- AI analysis results
- User tracking (status, notes)

### FollowUps
- Scheduled reminders
- Action types
- Completion status

### CrawlLogs
- Execution history
- Success/failure tracking
- Error messages

## Security Features

1. **Credential Encryption**: Fernet symmetric encryption
2. **No External Data**: All AI processing local
3. **Encrypted Transit**: HTTPS for notifications
4. **No API Keys Stored**: Uses environment variables
5. **Database Security**: PostgreSQL with authentication

## Performance Considerations

- **Concurrent Crawling**: Uses asyncio for parallel execution
- **Rate Limiting**: Respects platform limits
- **Caching**: Redis for session management
- **Lazy Loading**: Dashboard loads data on demand
- **Database Indexing**: On external_id, discovered_at

## Scalability

Current design handles:
- 10+ active searches
- 1000+ jobs tracked
- 30-minute refresh cycle

To scale further:
- Add Redis job queue (Celery)
- Implement distributed crawling
- Add multiple Selenium nodes
- Use connection pooling
